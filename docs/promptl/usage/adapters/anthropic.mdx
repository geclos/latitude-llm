---
title: Anthropic
description: Learn how to use PromptL with Anthropic
---

## Overview

PromptL integrates seamlessly with Anthropic’s API by using the `Anthropic` adapter. This ensures prompts are formatted correctly for their API and Node.js SDK, allowing you to generate dynamic prompts with ease.

<Note>
  **System Message Limitations**: Anthropic does not support system messages in the messages array. Instead:
  - PropmtL will automatically move the first system message to the `config` object.
  - System messages are not allowed after messages from other roles, and it will throw an error.
  - Since system messages are moved to the configuration section, Anthropic will fail if there are no other user or assistant messages in the conversation.
</Note>

---

## Basic Example

Here’s how to use PromptL with Anthropic’s API:

```typescript
import Anthropic from '@anthropic-ai/sdk'
import { Adapters, render } from 'promptl-ai'

const prompt = `
---
model: claude-3-opus-20240229
max_tokens: 1024
---

<user>
  Generate a joke about {{ topic }}.
</user>
`

const { messages, config } = await render({
  prompt,
  parameters: { topic: 'chickens' },
  adapter: Adapters.anthropic, // Specify the Anthropic adapter
})

const client = new Anthropic({ apiKey: YOUR_ANTHROPIC_API_KEY })
const response = await client.messages.create({
  ...config,
  messages,
})

console.log(response.content[0].text)
```

---

## Key Features

1. **Adapter-Specific Behavior**:
   - System messages are extracted and placed in the `config` object.
   - The `messages` array must contain non-system messages.
2. **Formatting**: PromptL formats messages in the format expected by Anthropic, ensuring compatibility.
3. **Support for Claude Models**: Works seamlessly with Anthropic’s Claude family of models.

---

## Troubleshooting

1. **Empty Messages Array**:
   - Ensure your prompt contains non-system messages. Anthropic’s API does not allow an empty `messages` array.
2. **Check Configuration**:
   - Anthropic always requires to define at least a `model` and `max_tokens` configuration.
3. **Error Handling**:
   ```typescript
   try {
     const response = await client.messages.create({
       ...config,
       messages,
     })
     console.log(response.content[0].text)
   } catch (error) {
     console.error('Error with Anthropic API:', error)
   }
   ```

---

## Next Steps

- [Learn More About Anthropic’s API](https://docs.anthropic.com/en/api/messages)
- Explore advanced PromptL features:
  - [Chains and Steps](syntax/chains)
  - [Prompt References](syntax/prompt-references)
