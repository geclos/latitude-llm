---
title: Overview
description: 'Learn how to create and connect evaluations to your prompts.'
---

## What is an evaluation?

Evaluations help you assess the quality of your LLM outputs. Latitude supports two types of evaluations:

- [**LLM evaluations**](/guides/evaluations/llm_as_judge_evaluations): Use LLM evaluators to score your LLM outputs.
- [**Manual evaluations (HITL)**](/guides/evaluations/manual_evaluations): Evaluate your LLM output with human feedback or code-based evaluations, and push the results to Latitude.
